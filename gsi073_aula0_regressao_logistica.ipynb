{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GSI073 - Tópicos Especiais de Inteligência Artificial\n",
        "\n",
        "## Definição dos dados"
      ],
      "metadata": {
        "id": "Mwsc0ViVertv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmZxMYLGefOh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Carregar dados\n",
        "iris = sklearn.datasets.load_iris()\n",
        "X = iris.data        # 4 features: sépalas e pétalas\n",
        "y = (iris.target == 1).astype(float)  # 1 se Versicolor, 0 caso contrário\n",
        "\n",
        "# 2. Dividir em treino (100 amostras) e teste (50 amostras)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    train_size=100,\n",
        "    test_size=50,\n",
        "    random_state=42  # para reprodutibilidade\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição do modelo e treinamento"
      ],
      "metadata": {
        "id": "nUv-LKlIe9Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Converter para tensores PyTorch\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 4. Definir modelo: regressão logística\n",
        "modelo = torch.nn.Linear(4, 1)  # 4 features → 1 saída"
      ],
      "metadata": {
        "id": "eg97DxIbe0tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execução do treinamento"
      ],
      "metadata": {
        "id": "Agjn3aQxfHOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Definir função de perda e algoritmo de otimização\n",
        "funcao_perda = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.1)\n",
        "\n",
        "# 6. Treino\n",
        "print(\"=== Iniciando Treinamento ===\\n\")\n",
        "for epoch in range(1000):\n",
        "    # Modo de treino\n",
        "    modelo.train()\n",
        "    optimizer.zero_grad()  # reseta gradiente senão acumula\n",
        "    outputs = modelo(X_train)\n",
        "    loss = funcao_perda(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Avaliação no conjunto de teste a cada 100 épocas\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        modelo.eval()  # modo de avaliação\n",
        "        with torch.no_grad():\n",
        "            test_outputs = modelo(X_test)\n",
        "            test_loss = funcao_perda(test_outputs, y_test)\n",
        "\n",
        "            # Calcular probabilidades\n",
        "            probabilities = torch.sigmoid(test_outputs)\n",
        "\n",
        "            # Calcular acurácia no teste\n",
        "            predictions = probabilities > 0.5\n",
        "            accuracy = (predictions == y_test).float().mean()\n",
        "\n",
        "            # Calcular AUC-ROC\n",
        "            y_test_np = y_test.numpy()\n",
        "            probabilities_np = probabilities.numpy()\n",
        "            auc_roc = roc_auc_score(y_test_np, probabilities_np)\n",
        "\n",
        "        print(f\"Época [{epoch+1}/1000], Loss Treino: {loss.item():.4f}, \"\n",
        "              f\"Loss Teste: {test_loss.item():.4f}, Acurácia: {accuracy.item():.4f}, \"\n",
        "              f\"AUC-ROC: {auc_roc:.4f}\")\n",
        "\n",
        "# 7. Avaliação final e busca do melhor threshold\n",
        "print(\"\\n=== Avaliação Final ===\\n\")\n",
        "modelo.eval()\n",
        "with torch.no_grad():\n",
        "    final_test_outputs = modelo(X_test)\n",
        "    final_probabilities = torch.sigmoid(final_test_outputs)\n",
        "\n",
        "    # Converter para numpy\n",
        "    y_test_np = y_test.numpy().flatten()\n",
        "    final_probabilities_np = final_probabilities.numpy().flatten()\n",
        "\n",
        "    # Calcular curva ROC\n",
        "    fpr, tpr, thresholds = roc_curve(y_test_np, final_probabilities_np)\n",
        "    final_auc_roc = roc_auc_score(y_test_np, final_probabilities_np)\n",
        "\n",
        "# 8. Encontrar o melhor threshold através da busca exaustiva\n",
        "print(\"=== Buscando Melhor Threshold ===\\n\")\n",
        "\n",
        "melhor_acuracia = 0\n",
        "melhor_threshold = 0.5\n",
        "melhor_vp = 0\n",
        "melhor_vn = 0\n",
        "melhor_fp = 0\n",
        "melhor_fn = 0\n",
        "resultados = []\n",
        "\n",
        "# Testar diversos thresholds de 0.0 a 1.0\n",
        "thresholds_teste = np.arange(0.0, 1.01, 0.01)\n",
        "\n",
        "for threshold in thresholds_teste:\n",
        "    # Fazer predições com o threshold atual\n",
        "    predictions = (final_probabilities_np >= threshold).astype(int)\n",
        "\n",
        "    # Calcular matriz de confusão\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_np, predictions).ravel()\n",
        "\n",
        "    # Calcular acurácia\n",
        "    acuracia = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "    # Armazenar resultados\n",
        "    resultados.append({\n",
        "        'threshold': threshold,\n",
        "        'acuracia': acuracia,\n",
        "        'vp': tp,\n",
        "        'vn': tn,\n",
        "        'fp': fp,\n",
        "        'fn': fn\n",
        "    })\n",
        "\n",
        "    # Atualizar melhor resultado\n",
        "    if acuracia > melhor_acuracia:\n",
        "        melhor_acuracia = acuracia\n",
        "        melhor_threshold = threshold\n",
        "        melhor_vp = tp\n",
        "        melhor_vn = tn\n",
        "        melhor_fp = fp\n",
        "        melhor_fn = fn\n",
        "\n",
        "# 9. Exibir resultados\n",
        "print(f\"Melhor Threshold: {melhor_threshold:.2f}\")\n",
        "print(f\"Melhor Acurácia: {melhor_acuracia:.4f}\")\n",
        "print(f\"\\nMatriz de Confusão no Melhor Threshold:\")\n",
        "print(f\"  Verdadeiros Positivos (VP): {melhor_vp}\")\n",
        "print(f\"  Verdadeiros Negativos (VN): {melhor_vn}\")\n",
        "print(f\"  Falsos Positivos (FP): {melhor_fp}\")\n",
        "print(f\"  Falsos Negativos (FN): {melhor_fn}\")\n",
        "print(f\"\\nAUC-ROC: {final_auc_roc:.4f}\")\n",
        "print(f\"Total de amostras de treino: {len(X_train)}\")\n",
        "print(f\"Total de amostras de teste: {len(X_test)}\")\n",
        "\n",
        "# Calcular métricas adicionais\n",
        "sensibilidade = melhor_vp / (melhor_vp + melhor_fn) if (melhor_vp + melhor_fn) > 0 else 0\n",
        "especificidade = melhor_vn / (melhor_vn + melhor_fp) if (melhor_vn + melhor_fp) > 0 else 0\n",
        "precisao = melhor_vp / (melhor_vp + melhor_fp) if (melhor_vp + melhor_fp) > 0 else 0\n",
        "\n",
        "print(f\"\\nMétricas Adicionais:\")\n",
        "print(f\"  Sensibilidade (Recall): {sensibilidade:.4f}\")\n",
        "print(f\"  Especificidade: {especificidade:.4f}\")\n",
        "print(f\"  Precisão: {precisao:.4f}\")\n",
        "\n",
        "# 10. Visualizações\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Gráfico 1: Curva ROC\n",
        "axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {final_auc_roc:.4f})')\n",
        "axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Classificador Aleatório')\n",
        "axes[0].set_xlim([0.0, 1.0])\n",
        "axes[0].set_ylim([0.0, 1.05])\n",
        "axes[0].set_xlabel('Taxa de Falsos Positivos (FPR)')\n",
        "axes[0].set_ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
        "axes[0].set_title('Curva ROC')\n",
        "axes[0].legend(loc=\"lower right\")\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Gráfico 2: Acurácia vs Threshold\n",
        "acuracias = [r['acuracia'] for r in resultados]\n",
        "thresholds_list = [r['threshold'] for r in resultados]\n",
        "axes[1].plot(thresholds_list, acuracias, color='green', lw=2)\n",
        "axes[1].axvline(x=melhor_threshold, color='red', linestyle='--',\n",
        "                label=f'Melhor Threshold = {melhor_threshold:.2f}')\n",
        "axes[1].axhline(y=melhor_acuracia, color='red', linestyle='--', alpha=0.5)\n",
        "axes[1].set_xlabel('Threshold')\n",
        "axes[1].set_ylabel('Acurácia')\n",
        "axes[1].set_title('Acurácia vs Threshold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "# Gráfico 3: Matriz de Confusão no Melhor Threshold\n",
        "cm = np.array([[melhor_vn, melhor_fp], [melhor_fn, melhor_vp]])\n",
        "im = axes[2].imshow(cm, cmap='Blues')\n",
        "\n",
        "# Adicionar valores nas células\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        text = axes[2].text(j, i, cm[i, j], ha=\"center\", va=\"center\",\n",
        "                           color=\"white\" if cm[i, j] > cm.max()/2 else \"black\",\n",
        "                           fontsize=20, fontweight='bold')\n",
        "\n",
        "axes[2].set_xticks([0, 1])\n",
        "axes[2].set_yticks([0, 1])\n",
        "axes[2].set_xticklabels(['Predito: Negativo', 'Predito: Positivo'])\n",
        "axes[2].set_yticklabels(['Real: Negativo', 'Real: Positivo'])\n",
        "axes[2].set_title(f'Matriz de Confusão\\n(Threshold = {melhor_threshold:.2f})')\n",
        "plt.colorbar(im, ax=axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 11. Mostrar top 5 melhores thresholds\n",
        "print(\"\\n=== Top 5 Melhores Thresholds ===\")\n",
        "resultados_ordenados = sorted(resultados, key=lambda x: x['acuracia'], reverse=True)\n",
        "for i, r in enumerate(resultados_ordenados[:5], 1):\n",
        "    print(f\"{i}. Threshold: {r['threshold']:.2f} | Acurácia: {r['acuracia']:.4f} | \"\n",
        "          f\"VP: {r['vp']}, VN: {r['vn']}, FP: {r['fp']}, FN: {r['fn']}\")"
      ],
      "metadata": {
        "id": "uuksjyq7e4Mt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}